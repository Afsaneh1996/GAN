{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV9p4fGmEHqz"
      },
      "source": [
        "# example of defining the generator model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "\tmodel = Sequential()\n",
        "\t# foundation for 7x7 image\n",
        "\tn_nodes = 128 * 7 * 7\n",
        "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((7, 7, 128)))\n",
        "\t# upsample to 14x14\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 28x28\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Conv2D(3, (7,7), activation='sigmoid', padding='same'))\n",
        "\treturn model\n",
        "\n",
        "# define the size of the latent space\n",
        "latent_dim = 100\n",
        "# define the generator model\n",
        "model = define_generator(latent_dim)\n",
        "# summarize the model\n",
        "model.summary()\n",
        "# plot the model\n",
        "plot_model(model, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}